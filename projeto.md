## **Escopo do Projeto de Engenharia de Dados na Sa√∫de no Brasil**

- [üí° **Contexto do Neg√≥cio**](#-contexto-do-neg√≥cio)
- [üéØ **Objetivos do Projeto**](#-objetivos-do-projeto)
- [üéõ **Principais Requisitos T√©cnicos**](#-principais-requisitos-t√©cnicos)
- [üõ† **Etapas do Projeto**](#-etapas-do-projeto)
    - [**1. Ingest√£o de Dados**](#1-ingest√£o-de-dados)
    - [**2. Armazenamento de Dados**](#2-armazenamento-de-dados)
    - [**3. Processamento e Transforma√ß√£o**](#3-processamento-e-transforma√ß√£o)
    - [**4. Modelagem Anal√≠tica e Curadoria**](#4-modelagem-anal√≠tica-e-curadoria)
    - [**5. Monitoramento e CI/CD**](#5-monitoramento-e-cicd)
- [üèÜ **Resultados Esperados**](#-resultados-esperados)

### üí° **Contexto do Neg√≥cio**

O projeto visa melhorar a efici√™ncia na an√°lise e utiliza√ß√£o de dados do Sistema √önico de Sa√∫de (SUS) para identificar padr√µes em interna√ß√µes hospitalares, prevenir complica√ß√µes em pacientes cr√¥nicos e otimizar recursos de sa√∫de. A plataforma ser√° criada para ingest√£o, transforma√ß√£o, an√°lise e disponibiliza√ß√£o de dados de sa√∫de p√∫blica, com foco em democratizar o acesso a dados para pesquisadores e gestores.

----------

## üéØ **Objetivos do Projeto**

1.  **Desenvolver uma pipeline robusta de dados** para ingest√£o e transforma√ß√£o de grandes volumes de dados de sa√∫de p√∫blica, com foco nos sistemas do SUS.
2.  **Analisar interna√ß√µes e tratamentos** para identificar padr√µes que podem auxiliar na preven√ß√£o de complica√ß√µes em doen√ßas cr√¥nicas como diabetes e hipertens√£o.
3.  **Facilitar a tomada de decis√£o** ao entregar dados prontos para uso em modelos anal√≠ticos e dashboards interativos.
4.  **Garantir escalabilidade e confiabilidade** por meio de uma arquitetura moderna utilizando cont√™ineres e servi√ßos gerenciados em nuvem.

----------

## üéõ **Principais Requisitos T√©cnicos**

-   **Docker**: Cria√ß√£o de imagens para pipelines de ingest√£o e transforma√ß√£o.
-   **Airflow**: Agendamento e monitoramento de tarefas.
-   **Apache Spark**: Processamento distribu√≠do de grandes volumes de dados.
-   **SQL**: Consultas para transformar e preparar dados.
-   **AWS S3**: Armazenamento escal√°vel e seguro.
-   **EKS**: Orquestra√ß√£o de containers para alta disponibilidade.
-   **CI/CD**: Deploy automatizado de mudan√ßas no c√≥digo.

----------

## üõ† **Etapas do Projeto**

### **1. Ingest√£o de Dados**

-   **Origem dos dados**:
    -   Arquivos CSV, JSON e Parquet dispon√≠veis no DATASUS e em portais estaduais de sa√∫de.
    -   Dados de APIs p√∫blicas do SUS e outros √≥rg√£os relacionados.
-   **Ferramentas e Tecnologias**:
    -   **Python**: Scripts para ingest√£o inicial e manipula√ß√£o dos dados.
    -   **Airflow**: Agendador de tarefas para automa√ß√£o do processo de ingest√£o.
    -   **Docker**: Cria√ß√£o de containers para executar servi√ßos de ingest√£o de forma isolada.

### **2. Armazenamento de Dados**

-   **Estrat√©gia de armazenamento**:
    -   Dados brutos: Salvos no **AWS S3** em camadas (Bronze).
    -   Dados processados: Ap√≥s ETL, armazenados nas camadas Silver e Gold.
    -   Compat√≠vel com processamento distribu√≠do no **Apache Spark**.
-   **Organiza√ß√£o**:
    -   Diret√≥rios segmentados por estado, tipo de dado e ano.
    -   Metadados gerenciados em um cat√°logo de dados no **AWS Glue**.

### **3. Processamento e Transforma√ß√£o**

-   **Pipeline de ETL**:
    -   Transforma√ß√£o e limpeza dos dados no **Apache Spark**.
    -   Uso de SQL para padronizar nomenclaturas e realizar agrega√ß√µes (ex.: sumariza√ß√£o de interna√ß√µes por tipo de hospital e munic√≠pio).
    -   Implementa√ß√£o de tarefas distribu√≠das para alta performance.
-   **Ferramentas e Tecnologias**:
    -   **Airflow** para orquestra√ß√£o.
    -   **Docker** e **Kubernetes** para execu√ß√£o em clusters.
    -   **Python** para valida√ß√£o e cria√ß√£o de scripts auxiliares.

### **4. Modelagem Anal√≠tica e Curadoria**

-   **Modelagem**:
    -   Desenvolvimento de tabelas anal√≠ticas (fatos e dimens√µes).
    -   Organiza√ß√£o no formato estrela ou floco de neve, dependendo da necessidade anal√≠tica.
-   **Entrega**:
    -   Dados otimizados para dashboards Power BI ou Tableau.
    -   Exporta√ß√£o de datasets para cientistas de dados via APIs.

### **5. Monitoramento e CI/CD**

-   **Monitoramento**:
    -   Implementa√ß√£o de monitoramento com m√©tricas de sucesso/falha das pipelines (ex.: logs de execu√ß√£o no Airflow e Spark UI).
    -   Alertas em casos de falha de execu√ß√£o.
-   **CI/CD**:
    -   Cria√ß√£o de pipelines de entrega cont√≠nua para scripts de ETL e imagens Docker.
    -   Deploy automatizado em clusters **EKS (Amazon Elastic Kubernetes Service)**.
    -   Uso de ferramentas como **GitHub Actions** ou **Azure DevOps**.

----------

## üèÜ **Resultados Esperados**

1.  **Dados limpos e organizados**: Acess√≠veis em um formato escal√°vel e pronto para an√°lise.
2.  **Insights de sa√∫de p√∫blica**: Identifica√ß√£o de padr√µes cr√≠ticos para melhorar o atendimento em doen√ßas cr√¥nicas.
3.  **Otimiza√ß√£o de custos em sa√∫de**: Suporte a pol√≠ticas p√∫blicas com base em evid√™ncias extra√≠das dos dados.
4.  **Sustentabilidade tecnol√≥gica**: Infraestrutura modular e escal√°vel para expans√£o futura.

----------

